{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mewtwo Freeza.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/pigiipanku/Mewtwo_Freeza/blob/master/Mewtwo_Freeza.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "aqI4FEbps5m9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "f0cf9d03-ea3d-4390-9d14-a5d7aefe7b6a"
      },
      "cell_type": "code",
      "source": [
        "#必要なファイルをダウンロード\n",
        "\n",
        "#model weight\n",
        "!wget \"https://www.dropbox.com/s/b24m53a6x7zlb5e/model.json?dl=1\" -nc -O ./model.json\n",
        "!wget \"https://www.dropbox.com/s/rzkk1gabm6ltvl8/weight.h5?dl=1\" -nc -O ./weight.h5\n",
        "!wget \"https://www.dropbox.com/s/kpow4we4fhjpx2v/train.zip?dl=1\" -nc -O ./train.zip\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists('./train'):\n",
        "  !unzip train.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘./model.json’ already there; not retrieving.\n",
            "File ‘./weight.h5’ already there; not retrieving.\n",
            "--2018-10-12 14:36:16--  https://www.dropbox.com/s/kpow4we4fhjpx2v/train.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/kpow4we4fhjpx2v/train.zip [following]\n",
            "--2018-10-12 14:36:17--  https://www.dropbox.com/s/dl/kpow4we4fhjpx2v/train.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8ef532599ce4c491bd8153aaba.dl.dropboxusercontent.com/cd/0/get/AS17sYuDsiUYBI1HH4bB9ieiDpjig-B-Z3qpqMTpJbK_5J-2YSoFVNouNafJ0hmttowRao3xYo9PkFw7EZJFUcdhpCbMEXhHvY5RmzdhnzDVAi7teZYJjNmszCoDWco0ODkYtWkLzcVc-2i97Hs0tcgCyMRbdZS7-1pCMJfaagUgAN-pkx4U5EgaK4LXQjof6Xs/file?dl=1 [following]\n",
            "--2018-10-12 14:36:17--  https://uc8ef532599ce4c491bd8153aaba.dl.dropboxusercontent.com/cd/0/get/AS17sYuDsiUYBI1HH4bB9ieiDpjig-B-Z3qpqMTpJbK_5J-2YSoFVNouNafJ0hmttowRao3xYo9PkFw7EZJFUcdhpCbMEXhHvY5RmzdhnzDVAi7teZYJjNmszCoDWco0ODkYtWkLzcVc-2i97Hs0tcgCyMRbdZS7-1pCMJfaagUgAN-pkx4U5EgaK4LXQjof6Xs/file?dl=1\n",
            "Resolving uc8ef532599ce4c491bd8153aaba.dl.dropboxusercontent.com (uc8ef532599ce4c491bd8153aaba.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc8ef532599ce4c491bd8153aaba.dl.dropboxusercontent.com (uc8ef532599ce4c491bd8153aaba.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8461597 (8.1M) [application/binary]\n",
            "Saving to: ‘./train.zip’\n",
            "\n",
            "./train.zip         100%[===================>]   8.07M  26.5MB/s    in 0.3s    \n",
            "\n",
            "2018-10-12 14:36:19 (26.5 MB/s) - ‘./train.zip’ saved [8461597/8461597]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "55lTbjDf2UQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e988684-5fba-4162-9f75-639e4e377c48"
      },
      "cell_type": "code",
      "source": [
        "#必要なライブラリをインポート\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, Model, model_from_json\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "27XJkeN0liwn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##ミュウツーvsフリーザ\n",
        "ディープラーニングでミュウツーとフリーザを画像認識していきます。\n",
        "\n",
        "###ミュウツー(ポケモン)\n",
        "![ミュウツー](https://www.dropbox.com/s/513apwjec943lmk/150.gif?dl=1)\n",
        "###フリーザ（DRAGON BALL)\n",
        "![代替テキスト](https://www.dropbox.com/s/boxy5zx754g68fh/%E3%83%95%E3%83%AA%E3%83%BC%E3%82%B6_%E3%83%89%E3%83%A9%E3%82%B4%E3%83%B3%E3%83%9C%E3%83%BC%E3%83%AB%E3%83%95%E3%82%A1%E3%82%A4%E3%82%BF%E3%83%BC%E3%82%BA.png?dl=1)\n",
        "\n",
        "\n",
        "画像認識は、\n",
        "\n",
        "**ミュウツー**の画像が与えられれば、その画像に写っているのは**ミュウツー**と、\n",
        "\n",
        "**フリーザ**の画像が与えられれば、その画像に写っているのは**フリーザ**と判断することです。\n",
        "\n",
        "\n",
        "ディープラーニング（Deep Newral Network)を使って画像認識器を構築していきます。ディープラーニングのなかでも画像の処理を得意とする**Convolutional Neural Network**(以下CNN)を使います。\n",
        "\n",
        "今回は、なにかとよく似ていると言われがちな**ミュウツー**と**フリーザ**の画像認識器を構築していきます。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Xc8TUL8K62Mv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##画像認識\n",
        "\n",
        "###なんでコンピュータは画像認識ごときもできなかったの？\n",
        "\n",
        "私達、人間にとっては画像認識は簡単です。**ミュウツー**と**フリーザ**なんて１秒もかからずに見分けることができるでしょう。私達にとっては画像認識なんかよりも、素因数分解のほうがよっぽど大変です。\n",
        "\n",
        "\n",
        "では、なぜ画像認識をコンピュータで行うことが難しいのか、理由を考えてみましょう。そもそも、コンピュータに画像はどのようにみえているのでしょうか？コンピュータにとって画像とは、輝度値（0~255の値）またはRGB値(赤・緑・青の割合を0~255で表した値)　が二次元に並んだデータです。\n",
        "\n",
        "では、ある画像の輝度値を二次元に並べ、グラフで表示した図を下に示します。このグラフからなんの画像を表しているかわかるでしょうか？\n",
        "###輝度値の二次元グラフ\n",
        "![](https://www.dropbox.com/s/xh8t36ezw7882mi/IMG_4297.JPG?dl=1 =300x300)\n",
        "\n",
        "この画像を見て、ずばり何を意味するか分かる方はほとんどいないと思います。ル○ーシュレベルの天才しかわからないと思います。\n",
        "\n",
        "この輝度値が表す実際の画像を下に示します。\n",
        "###輝度値のグラフが表すもの\n",
        "![](https://www.dropbox.com/s/pbq7myzwa9102ze/IMG_4298.JPG?dl=1 =300x300)\n",
        "\n",
        "この画像を見れば、誰でもひと目でりんごの絵だとわかりますね。みなみけの次女でもわかります。\n",
        "\n",
        "しかし、コンピュータから見えている画像は輝度値の二次元グラフのようなただの数字の集まりです。人間は物体の映る画像を見ると、瞬時に物体のまとまりを認識でき、まとまりが何を表しているかを理解することができます。ところが、コンピュータにとってそれが容易でないことは、人間が輝度値の二次元グラフからりんごを想像できないのと同じです。\n",
        "\n",
        "画像認識が難しい問題であることがご理解いただけたと思います。\n",
        "\n",
        "###画像認識の難しさはまだあるぜ！\n",
        "\n",
        "さらに、画像認識が難しい理由を説明します。画像認識を行うには、写っている物体の種類を判定するための基準が必要です。しかし、その判定基準を作るのが難しいです。\n",
        "\n",
        "例えば、下の画像に写っている果物を判別する問題で考えてみます。\n",
        "###フルーツバスケット♪\n",
        "![](https://www.dropbox.com/s/9coig3ixj1ir587/e0142313_15354059.jpg?dl=1)\n",
        "\n",
        "色で区別する場合はどうでしょうか？色を使えば、「みかん」と「りんご」を見分けるのは簡単ですね。ですが、「みかん」と「かき」の場合は両方共オレンジだから区別するのは難しいです。\n",
        "\n",
        "それでは、形で区別した場合はどうでしょうか？「バナナ」と「グレープフルーツ」は簡単に区別できそうです。しかし、「りんご」と「なし」は両方とも同じ形をしているので区別するのが難しいです。色と形の両方を使えば、いろいろ区別できそうです。それでも、「みかん」と「かき」はどうでしょうか？\n",
        "\n",
        "このように考えると、画像認識の仕組みを作成することが単純でないことがわかります。だから、機械にその判断基準を決めさせるべきです。\n",
        "\n",
        "そこで、機械学習やディープラーニングは手段が明確に決まらないような処理をコンピュータで処理する手段として有効です。画像認識はまさにこれにあてはまります。\n",
        "\n",
        "その中の一つとして、教師ありの機械学習のCNNは最も有効な手段です。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "V6B39U8svyA2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##CNN(Convolution Neural Network)の概要\n",
        "####CNN\n",
        "![代替テキスト](https://www.dropbox.com/s/5n4dnvin9a7l8dq/cnn_thumb.jpg?dl=1)\n",
        "\n",
        "###ざっくりした説明\n",
        "CNNは画像認識で最もよく使われる手法で、最近の自動運転技術とかにも使われています。\n",
        "\n",
        "教師ありの機械学習のCNNをざっくりと説明してしまえば、大量の画像と画像に写っている物体名の組を、訓練データとして用意します。そして、CNNの入力層に画像を、出力層に物体名を入れて、訓練すればいい。それだけです。\n",
        "\n",
        "\n",
        "###ちょっと具体的な説明\n",
        "####CNNの設計図\n",
        "![](https://www.dropbox.com/s/v4l47n3ky8s23sn/IMG_4301.JPG?dl=1)\n",
        "\n",
        "CNNは**畳み込み層(Conv)**と**ブーリング層(Pooling)**を持つニューラルネットワークを利用したアルゴリズムです。\n",
        "\n",
        "**全結合層(Dense)**という通常のニューラルネットワークの代表的な層も持ちます。\n",
        "\n",
        "CNNを使って、ミュウツーとフリーザを画像認識します。\n",
        "みなさんには**畳み込み層(Conv)**と**ブーリング層(Pooling)**と**全結合層(Dense)**の3つの層を組み合わせてCNNを構成してもらいます。\n",
        "\n",
        "これからそれを説明します。**わからなければ\"層\"の説明は読まなくても、課題をすすめることができます**\n",
        "\n",
        "###畳み込み層\n",
        "![](https://www.dropbox.com/s/4bwci7qnrgqxvu6/IMG_4302.JPG?dl=1)\n",
        "畳み込み層とは、ある画像の局所的な部分を抽象化する役割を果たします。上の図では前の層のノードのうち局所的な部分が、次の層の３つの部分と接続されています。このとき、それぞれ違った部分で抽象化が行われます。抽象化とは、ある特徴を浮き立たせるような効果を指します。\n",
        "\n",
        "つまり、畳み込み層は画像の局所的な部分の特徴を様々な方法で浮き立たせます。\n",
        "\n",
        "畳み込み層は\n",
        "Conv2D(**f**,**k**,padding='same',activation='relu')\n",
        "で使えます。\n",
        "\n",
        "**f**には32,64のどちらかを選択してください。**f**は上の図の次の層の数を決めます。上の図では3です。\n",
        "\n",
        "**k**には(2,2),(3,3),(4,4),(5,5)のどれかを選択してください。**k**は上の図の前の層の近隣にあるノードの集合を表しています。上の図では(3,3)です。\n",
        "\n",
        "\n",
        "###プーリング層\n",
        "![](https://www.dropbox.com/s/11eny0i53ukyjbp/IMG_4303.JPG?dl=1)\n",
        "プーリング層は前の層の局所的な部分をまとめ上げる処理を指します。特に、局所的な部分の最大値を取る処理は「最大プーリング」と呼ばれます。プーリング層は、位置変更への感度を下げることで、小さな平行移動に対する普遍性をもたせる役割を果たします。なぜなら、少しの平行移動があってもプーリング層は局所的な最大値を次の層に返すので、つぎの層の値はほぼ変わりません。\n",
        "\n",
        "プーリング層は\n",
        "MaxPooling2D(p)\n",
        "で使えます。\n",
        "\n",
        "pには(2,2),(3,3),(4,4)のどれかを選択してください。pは上の図で前の層の最大値を取る範囲を示します。上の図だと、(3,3)です。\n",
        "\n",
        "###全結合層\n",
        "![](https://www.dropbox.com/s/nkjyoquq3r7j13r/IMG_4304.JPG?dl=1)\n",
        "\n",
        "前の層と自分の層をすべて結ばれています。\n",
        "全結合層では、処理するための計算量は大きくなる傾向があります。ですが、複雑なことができるようになります。全結合層は最後の方によく使われます。\n",
        "\n",
        "全結合層は\n",
        "Dense(n)\n",
        "でつかえます。\n",
        "\n",
        "nには32,64,128,256,512を選択してください。これはノードの数で、上の図の左は４、右は２です。\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ulDbJITAYyC7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##プログラミング課題\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   畳み込み層は Conv2D(**f**,**k**,padding='same',activation='relu') で使えます。\n",
        "\n",
        "**f**には32,64のどちらかを選択してください。**f**は上の図の次の層の数を決めます。上の図では3です。\n",
        "\n",
        "**k**には(2,2),(3,3),(4,4),(5,5)のどれかを選択してください。**k**は上の図の前の層の近隣にあるノードの集合を表しています。上の図では(3,3)です。\n",
        "*   プーリング層は MaxPooling2D(*p*) で使えます。\n",
        "\n",
        "**p**には(2,2),(3,3),(4,4)のどれかを選択してください。**p**は上の図で前の層の最大値を取る範囲を示します。上の図だと、(3,3)です。\n",
        "\n",
        "\n",
        "*   全結合層は Dense(**n**) でつかえます。\n",
        "\n",
        "**n**には32,64,128,256,512を選択してください。これはノードの数で、上の図の左は４、右は２です。\n",
        "\n",
        "\n",
        "層を追加したいときはmodel.add()の()のなかにその層を入れてください\n",
        "\n",
        "\n",
        "注意としては、はじめはConv2Dから始めてください。そして、input_shape=(img_height, img_width, 3)をそこだけ入れてください。\n",
        "\n",
        "Conv2DとMaxPoolingを組み合わせて前半を、Denseを使って後半を構成してください。\n",
        "\n",
        "まずは一つの手本を見せます。"
      ]
    },
    {
      "metadata": {
        "id": "dbV-4Ds3eLY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "e5530d9c-2f84-47b9-aacf-3fc9fa66aacd"
      },
      "cell_type": "code",
      "source": [
        "#例\n",
        "num_classes = 2\n",
        "img_height, img_width = 150, 150\n",
        "\n",
        "def Mynet():\n",
        "    model = Sequential()\n",
        "    #前半\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(img_height, img_width, 3)))\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #前半終了\n",
        "    model.add(Flatten())\n",
        "    #後半\n",
        "    model.add(Dense(32))\n",
        "    model.add(Dense(32))\n",
        "    #後半終了\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "    return model\n",
        "model = Mynet()\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 150, 150, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 75, 75, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 75, 75, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 87616)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2803744   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 2,870,434\n",
            "Trainable params: 2,870,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OGK3Nj6_fyD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "じゃあ実際に前半と前半修了の間にConv2DとMaxPooling2Dをくみあわせて、後半はDenseをくみあわせて、CNNを構築して見てください。数字や層の数は変えても大丈夫です。"
      ]
    },
    {
      "metadata": {
        "id": "6mj0yA9LfrJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "7ffd72c4-4527-446e-ab1f-21baab8ff5ce"
      },
      "cell_type": "code",
      "source": [
        "#課題\n",
        "num_classes = 2\n",
        "img_height, img_width = 150, 150\n",
        "\n",
        "def Mynet():\n",
        "    model = Sequential()\n",
        "    \n",
        "    #括弧の中身を消しています。括弧の中身を入力して実行してみましょう。わからなかったらスタッフに聞いてね!！\n",
        "    \n",
        "    #前半\n",
        "                       #↓ここには(2,2)や(6,6)をいれる\n",
        "    model.add(Conv2D(, (, ), padding='same', activation='relu', input_shape=(img_height, img_width, 3)))\n",
        "                   #↑ここには32か64をいれる\n",
        "      \n",
        "    #ここから下は上と同じようにやる\n",
        "    model.add(Conv2D(, (, ), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D((, )))\n",
        "\n",
        "    model.add(Conv2D(, (, ), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(, (, ), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    #前半終了\n",
        "    model.add(Flatten())\n",
        "    #後半\n",
        "    \n",
        "                  #↓ここには32や64をいれる\n",
        "    model.add(Dense())\n",
        "    model.add(Dense())\n",
        "    #後半終了\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "model = Mynet()\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-1fd82027d97a>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    model.add(Conv2D(, (, ), padding='same', activation='relu', input_shape=(img_height, img_width, 3)))\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "O9TR5mlOgzDP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "じゃあこのモデルを学習させていきましょう。\n",
        "\n",
        "その前に訓練させる画像を観察する必要があります。フリーザ、ミュウツーの画像を見ましょう。\n",
        "\n",
        "下のコードを実行してください。"
      ]
    },
    {
      "metadata": {
        "id": "ZmS2duP2lsSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display_dir = './train/000Freeza'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(8):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "  \n",
        "display_dir = './train/001Mewtoo'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "for i in range(8,16):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jalo6pNk_T5S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上の図で、\n",
        "\n",
        "上部分にフリーザ、下部分にミュウツーが見れると思います。８枚ずつしかありませんが、実際は２０枚ずつ以上あります。\n",
        "\n",
        "次に、この画像データをCNNが学習しやすい形に変えていきます。\n",
        "\n",
        "下のコードを実行してください。"
      ]
    },
    {
      "metadata": {
        "id": "1hhFfCJglsW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "classes = {'000Freeza','001Mewtoo'}\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory = 'train',\n",
        "    target_size = (img_width, img_height),\n",
        "    class_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory='valid',\n",
        "    target_size=(img_width, img_height),\n",
        "    class_mode='categorical',\n",
        "    batch_size= batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "model = Mynet()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = SGD(lr = 1e-4, momentum = 0.9),\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3I7dh4W6iCu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "画像データをCNNが学習させやすい形に変換できました。\n",
        "\n",
        "次に、このデータを先程作ったCNNに読み込ませて、学習させていきます。\n",
        "\n",
        "下のコードを実行すると、CNNを学習させることができます。epochsを変えれば、学習数を変えることができます。"
      ]
    },
    {
      "metadata": {
        "id": "ZXG9g-krlsc6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs =20 #ここを変えれば学習数が変えられる\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch= int((50-1)/batch_size) + 1,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps = int((20-1)/batch_size) + 1,\n",
        "    epochs= epochs,\n",
        "    initial_epoch = 0\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOy80uoiAonI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "学習が完了しました。\n",
        "\n",
        "では、精度を見ていきましょう。\n",
        "\n",
        "下のコードを実行すると、epochごとの**正解率**を見ることができます。"
      ]
    },
    {
      "metadata": {
        "id": "JDajaSU7lsf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"acc\"])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['acc','val_acc'],loc = 'lower right')\n",
        "plt.ylim(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qrJ25jJ39LPA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上のグラフは学習しているときの、訓練データの正解率です。\n",
        "横軸がepoch数(学習数)、縦軸が正解率です。\n",
        "\n",
        "訓練データがきちんと判定できているか確かめます。\n",
        "上の図で画像の上に書いてある、「Mewtoo,Freeza」が、画像に対してのCNNの判断です。\n",
        "おそらく、訓練データの正解率はけっこう高いので、いい感じに当たっていると思います。\n",
        "下のコードを実行してみてください。"
      ]
    },
    {
      "metadata": {
        "id": "mGrjqn196pdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label = list(classes)\n",
        "display_dir = './train/000Freeza'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(8):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  temp_img_array=img_to_array(temp_img)\n",
        "  temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "  temp_img_array=temp_img_array.reshape((1,150,150,3))\n",
        "  img_pred=model.predict(temp_img_array)\n",
        "  plt.title(label[np.argmax(img_pred)])\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "  \n",
        "display_dir = './train/001Mewtoo'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(8):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  temp_img_array=img_to_array(temp_img)\n",
        "  temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "  temp_img_array=temp_img_array.reshape((1,150,150,3))\n",
        "  img_pred=model.predict(temp_img_array)\n",
        "  plt.title(label[np.argmax(img_pred)])\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YFxs6lRw9hSA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ですが、訓練データだけの正解率が高いだけでは、ただの訓練データだけを見分けられるCNNです。実際に精度を確かめるなら、訓練データに入れていない画像を用いて、検証する必要があります。そのためのデータを交差検証データといいます。\n",
        "\n",
        "これから\n",
        "\n",
        "交差検証データを見せ、\n",
        "\n",
        "CNNによる交差検証データの精度が学習とともにどう変化しているか、\n",
        "\n",
        "最後に交差検証データをCNNに判断させます。"
      ]
    },
    {
      "metadata": {
        "id": "uQoFIkLSlsis",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display_dir = './valid/000Freeza'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(8):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "  \n",
        "display_dir = './valid/001Mewtoo'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "for i in range(8,16):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i-8]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y62jcVEgC9SH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このデータは訓練データに含まれていない交差検証データです。次は、CNNの交差検証データの正解率を学習とともに示したグラフです。\n"
      ]
    },
    {
      "metadata": {
        "id": "Bij90dYQlsla",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"val_acc\"])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['acc','val_acc'],loc = 'lower right')\n",
        "plt.ylim(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GzTk2Jd6DIXp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "訓練データよりかは良くなかったと思われます。\n",
        "最後にこれをテストします。"
      ]
    },
    {
      "metadata": {
        "id": "nYMCeBYKlsoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label = list(classes)\n",
        "display_dir = './valid/000Freeza'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(8):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  temp_img_array=img_to_array(temp_img)\n",
        "  temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "  temp_img_array=temp_img_array.reshape((1,150,150,3))\n",
        "  img_pred=model.predict(temp_img_array)\n",
        "  plt.title(label[np.argmax(img_pred)])\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "  \n",
        "display_dir = './valid/001Mewtoo'\n",
        "files = os.listdir(display_dir)\n",
        "img = random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(8):\n",
        "  temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.imshow(temp_img)\n",
        "  temp_img_array=img_to_array(temp_img)\n",
        "  temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "  temp_img_array=temp_img_array.reshape((1,150,150,3))\n",
        "  img_pred=model.predict(temp_img_array)\n",
        "  plt.title(label[np.argmax(img_pred)])\n",
        "  plt.xticks([]),plt.yticks([])\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJiB7Ng4EM51",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "おそらくあまりうまく行ってないと思います。\n",
        "\n",
        "正直、この少ない時間で交差検証データの精度を上げるのは難しいです。交差検証データの精度を上げるためには時間をかける必要があります。だから、今回は訓練データをしっかりと判別させることはできましたが、まだ訓練データに含まれていない画像を判別させることはできないです。\n",
        "\n",
        "ディープラーニングは交差検証データの正解率を上げることで、汎用性を上げています。交差検証データが上がれば、一般化ができたと言えるので大事です。\n",
        "\n",
        "最後に、こちら側で構築した、交差検証データの正解率を上げたCNNを見せます。このCNNは訓練画像を1000枚以上でよりフリーザとミュウツーを見分けられるようになっています。\n",
        "\n",
        "下のコードを実行すれば、判別例と正解率がみれます。"
      ]
    },
    {
      "metadata": {
        "id": "F6cRZ3B5lsrG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load model and weights\n",
        "json_string=open('model.json').read()\n",
        "model=model_from_json(json_string)\n",
        "model.load_weights('weight.h5')\n",
        "\n",
        "model.compile(optimizer=SGD(lr=1e-4,momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "display_dir = 'valid/000Freeza'\n",
        "#predict model and display images\n",
        "files=os.listdir(display_dir)\n",
        "img=random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "    plt.subplot(4,5,i+1)\n",
        "    plt.imshow(temp_img)\n",
        "    #Images normalization\n",
        "    temp_img_array=img_to_array(temp_img)\n",
        "    temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "    temp_img_array=temp_img_array.reshape((1,150,150,3))\n",
        "    #predict image\n",
        "    img_pred=model.predict(temp_img_array)\n",
        "    plt.title(label[np.argmax(img_pred)])\n",
        "    #eliminate xticks,yticks\n",
        "    plt.xticks([]),plt.yticks([])\n",
        "\n",
        "display_dir = 'valid/001Mewtoo'\n",
        "#predict model and display images\n",
        "files=os.listdir(display_dir)\n",
        "img=random.sample(files,len(files))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(150,150))\n",
        "    plt.subplot(4,5,i+11)\n",
        "    plt.imshow(temp_img)\n",
        "    #Images normalization\n",
        "    temp_img_array=img_to_array(temp_img)\n",
        "    temp_img_array=temp_img_array.astype('float32')/255.0\n",
        "    temp_img_array=temp_img_array.reshape((1,150,150,3))\n",
        "    #predict image\n",
        "    img_pred=model.predict(temp_img_array)\n",
        "    plt.title(label[np.argmax(img_pred)])\n",
        "    #eliminate xticks,yticks\n",
        "    plt.xticks([]),plt.yticks([])\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "score=model.evaluate_generator(valid_generator)\n",
        "print('\\n valid_acc:',score[1]*100,'%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIKcgvrIECaa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Congratulations!!\n",
        "\n",
        "\n",
        "これであなたは画像認識の基本を抑えられたと思います。\n",
        "\n",
        "CNNも同様にです。\n",
        "\n",
        "他の画像認識（顔認証、自動運転）などもこのCNNの応用です。面白いので、調べてみてください♪。\n",
        "\n"
      ]
    }
  ]
}